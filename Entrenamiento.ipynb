{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import psutil\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_por_tamaño():\n",
    "    variables = {k: sys.getsizeof(v) for k, v in globals().items() if not k.startswith('_')}\n",
    "    \n",
    "    variables_en_gb = {k: v / 1024**3 for k, v in variables.items()}\n",
    "    \n",
    "    tipos_variables = {k: type(v).__name__ for k, v in globals().items() if not k.startswith('_')}\n",
    "    \n",
    "    df = pd.DataFrame({'Variable': list(variables_en_gb.keys()),\n",
    "                       'Tipo': list(tipos_variables.values()),\n",
    "                       'Tamaño_GB': list(variables_en_gb.values())})\n",
    "    \n",
    "    df = df.sort_values('Tamaño_GB', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Mostrar la memoria disponible\n",
    "    memoria_disponible()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def Gb_por_variable(variable):\n",
    "    \n",
    "    print(sys.getsizeof(variable)/(1024**3))\n",
    "    memoria_disponible()\n",
    "\n",
    "def memoria_disponible():\n",
    "    mem = psutil.virtual_memory()\n",
    "    mem_total_gb = mem.total / (1024 ** 3)  # Memoria total en GB\n",
    "    mem_disponible_gb = mem.available / (1024 ** 3)  # Memoria disponible en GB\n",
    "\n",
    "    print(\"Memoria Total:\", mem_total_gb, \"GB\")\n",
    "    print(\"Memoria Disponible:\", mem_disponible_gb, \"GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo= 'Pkl/df_temp.pkl'\n",
    "# Cargar el DataFrame desde el archivo .pkl\n",
    "with open(archivo, 'rb') as archivo_pkl:\n",
    "    submatrices_diccionario_trabajadas = pickle.load(archivo_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria Total: 15.411502838134766 GB\n",
      "Memoria Disponible: 2.982524871826172 GB\n"
     ]
    }
   ],
   "source": [
    "archivo= 'Pkl/train_dict_Columnas_worked.pkl'\n",
    "# Cargar el DataFrame desde el archivo .pkl\n",
    "with open(archivo, 'rb') as archivo_pkl:\n",
    "    train_dict_Columnas_worked = pickle.load(archivo_pkl)\n",
    "train_dict={}\n",
    "train_dict['Columnas_Worked']=train_dict_Columnas_worked\n",
    "memoria_disponible()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria Total: 15.411502838134766 GB\n",
      "Memoria Disponible: 2.6760482788085938 GB\n"
     ]
    }
   ],
   "source": [
    "archivo= 'Pkl/Cluster_Info.pkl'\n",
    "# Cargar el DataFrame desde el archivo .pkl\n",
    "with open(archivo, 'rb') as archivo_pkl:\n",
    "    Cluster_Info = pickle.load(archivo_pkl)\n",
    "memoria_disponible()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explorar_una_matriz(submatriz):\n",
    "    return pd.DataFrame(submatrices_diccionario_trabajadas[submatriz],columns=train_dict['Columnas_Worked'])\n",
    "\n",
    "col_dummies=  ['Semana']\n",
    "indices_cat = [i for i, col in enumerate(train_dict['Columnas_Worked']) if col in col_dummies]\n",
    "indices_num = [i for i, col in enumerate(train_dict['Columnas_Worked']) if col not in col_dummies]\n",
    "\n",
    "Dict_Columnas_Dummizadas = {}\n",
    "Dict_nombres_de_columnas_df_dummizadas = {}\n",
    "\n",
    "def Duminizar_numpy(submatriz):\n",
    "    matriz_final=submatrices_diccionario_trabajadas[submatriz][:,indices_num]\n",
    "    columnas_final = train_dict['Columnas_Worked'][indices_num]\n",
    "    \n",
    "    for col in indices_cat:\n",
    "        onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "        one_hot_column = onehot_encoder.fit_transform(submatrices_diccionario_trabajadas[submatriz][:,col].reshape(-1, 1))\n",
    "        one_hot_column_names=  onehot_encoder.get_feature_names_out([train_dict['Columnas_Worked'][col]])\n",
    "        columnas_final = np.concatenate((columnas_final ,one_hot_column_names))\n",
    "        matriz_final = np.concatenate((matriz_final,one_hot_column), axis=1)\n",
    "\n",
    "    Dict_Columnas_Dummizadas[submatriz] = matriz_final\n",
    "    Dict_nombres_de_columnas_df_dummizadas[submatriz] = columnas_final\n",
    "    submatrices_diccionario_trabajadas[submatriz]= 0\n",
    "    del matriz_final,columnas_final \n",
    "\n",
    "valores_unicos = np.unique([valor for array in Dict_nombres_de_columnas_df_dummizadas.values() for valor in array])\n",
    "Dict_all_Columns = {}\n",
    "\n",
    "def ajustar_a_columnas_restantes(submatriz):\n",
    "    df_temp = pd.DataFrame(Dict_Columnas_Dummizadas[submatriz],columns=Dict_nombres_de_columnas_df_dummizadas[submatriz])\n",
    "    columnas_faltantes = [col for col in valores_unicos if col not in df_temp.columns]\n",
    "\n",
    "    for col in columnas_faltantes:\n",
    "        df_temp[col] = 0  # Puedes cambiar el valor si deseas algo diferente\n",
    "\n",
    "    return df_temp[valores_unicos].to_numpy()\n",
    "\n",
    "def unir_y_borrar():\n",
    "    for submatriz in Dict_all_Columns.keys():\n",
    "        print(str(submatriz)+ '/' + str(len(list(Dict_all_Columns.keys()))) +'|'+str(round(submatriz/len(list(Dict_all_Columns.keys()))*100,3))+'%')\n",
    "        if submatriz ==1:\n",
    "            All_junto = Dict_all_Columns[submatriz]\n",
    "        else:\n",
    "            All_junto = np.concatenate([All_junto,Dict_all_Columns[submatriz]],axis=0)\n",
    "        Dict_all_Columns[submatriz]=0\n",
    "    return All_junto\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria Total: 15.411502838134766 GB\n",
      "Memoria Disponible: 0.5375099182128906 GB\n",
      "1/149|0.671%\n",
      "2/149|1.342%\n",
      "3/149|2.013%\n",
      "4/149|2.685%\n",
      "5/149|3.356%\n",
      "6/149|4.027%\n",
      "7/149|4.698%\n",
      "8/149|5.369%\n",
      "9/149|6.04%\n",
      "10/149|6.711%\n",
      "11/149|7.383%\n",
      "12/149|8.054%\n",
      "13/149|8.725%\n",
      "14/149|9.396%\n",
      "15/149|10.067%\n",
      "16/149|10.738%\n",
      "17/149|11.409%\n",
      "18/149|12.081%\n",
      "19/149|12.752%\n",
      "20/149|13.423%\n",
      "21/149|14.094%\n",
      "22/149|14.765%\n",
      "23/149|15.436%\n",
      "24/149|16.107%\n",
      "25/149|16.779%\n",
      "26/149|17.45%\n",
      "27/149|18.121%\n",
      "28/149|18.792%\n",
      "29/149|19.463%\n",
      "30/149|20.134%\n",
      "31/149|20.805%\n",
      "32/149|21.477%\n",
      "33/149|22.148%\n",
      "34/149|22.819%\n",
      "35/149|23.49%\n",
      "36/149|24.161%\n",
      "37/149|24.832%\n",
      "38/149|25.503%\n",
      "39/149|26.174%\n",
      "40/149|26.846%\n",
      "41/149|27.517%\n",
      "42/149|28.188%\n",
      "43/149|28.859%\n",
      "44/149|29.53%\n",
      "45/149|30.201%\n",
      "46/149|30.872%\n",
      "47/149|31.544%\n",
      "48/149|32.215%\n",
      "49/149|32.886%\n",
      "50/149|33.557%\n",
      "51/149|34.228%\n",
      "52/149|34.899%\n",
      "53/149|35.57%\n",
      "54/149|36.242%\n",
      "55/149|36.913%\n",
      "56/149|37.584%\n",
      "57/149|38.255%\n",
      "58/149|38.926%\n",
      "59/149|39.597%\n",
      "60/149|40.268%\n",
      "61/149|40.94%\n",
      "62/149|41.611%\n",
      "63/149|42.282%\n",
      "64/149|42.953%\n",
      "65/149|43.624%\n",
      "66/149|44.295%\n",
      "67/149|44.966%\n",
      "68/149|45.638%\n",
      "69/149|46.309%\n",
      "70/149|46.98%\n",
      "71/149|47.651%\n",
      "72/149|48.322%\n",
      "73/149|48.993%\n",
      "74/149|49.664%\n",
      "75/149|50.336%\n",
      "76/149|51.007%\n",
      "77/149|51.678%\n",
      "78/149|52.349%\n",
      "79/149|53.02%\n",
      "80/149|53.691%\n",
      "81/149|54.362%\n",
      "82/149|55.034%\n",
      "83/149|55.705%\n",
      "84/149|56.376%\n",
      "85/149|57.047%\n",
      "86/149|57.718%\n",
      "87/149|58.389%\n",
      "88/149|59.06%\n",
      "89/149|59.732%\n",
      "90/149|60.403%\n",
      "91/149|61.074%\n",
      "92/149|61.745%\n",
      "93/149|62.416%\n",
      "94/149|63.087%\n",
      "95/149|63.758%\n",
      "96/149|64.43%\n",
      "97/149|65.101%\n",
      "98/149|65.772%\n",
      "99/149|66.443%\n",
      "100/149|67.114%\n",
      "101/149|67.785%\n",
      "102/149|68.456%\n",
      "103/149|69.128%\n",
      "104/149|69.799%\n",
      "105/149|70.47%\n",
      "106/149|71.141%\n",
      "107/149|71.812%\n",
      "108/149|72.483%\n",
      "109/149|73.154%\n",
      "110/149|73.826%\n",
      "111/149|74.497%\n",
      "112/149|75.168%\n",
      "113/149|75.839%\n",
      "114/149|76.51%\n",
      "115/149|77.181%\n",
      "116/149|77.852%\n",
      "117/149|78.523%\n",
      "118/149|79.195%\n",
      "119/149|79.866%\n",
      "120/149|80.537%\n",
      "121/149|81.208%\n",
      "122/149|81.879%\n",
      "123/149|82.55%\n",
      "124/149|83.221%\n",
      "125/149|83.893%\n",
      "126/149|84.564%\n",
      "127/149|85.235%\n",
      "128/149|85.906%\n",
      "129/149|86.577%\n",
      "130/149|87.248%\n",
      "131/149|87.919%\n",
      "132/149|88.591%\n",
      "133/149|89.262%\n",
      "134/149|89.933%\n",
      "135/149|90.604%\n",
      "136/149|91.275%\n",
      "137/149|91.946%\n",
      "138/149|92.617%\n",
      "139/149|93.289%\n",
      "140/149|93.96%\n",
      "141/149|94.631%\n",
      "142/149|95.302%\n",
      "143/149|95.973%\n",
      "144/149|96.644%\n",
      "145/149|97.315%\n",
      "146/149|97.987%\n",
      "147/149|98.658%\n",
      "148/149|99.329%\n",
      "149/149|100.0%\n",
      "1/149|0.671%\n",
      "2/149|1.342%\n",
      "3/149|2.013%\n",
      "4/149|2.685%\n",
      "5/149|3.356%\n",
      "6/149|4.027%\n",
      "7/149|4.698%\n",
      "8/149|5.369%\n",
      "9/149|6.04%\n",
      "10/149|6.711%\n",
      "11/149|7.383%\n",
      "12/149|8.054%\n",
      "13/149|8.725%\n",
      "14/149|9.396%\n",
      "15/149|10.067%\n",
      "16/149|10.738%\n",
      "17/149|11.409%\n",
      "18/149|12.081%\n",
      "19/149|12.752%\n",
      "20/149|13.423%\n",
      "21/149|14.094%\n",
      "22/149|14.765%\n",
      "23/149|15.436%\n",
      "24/149|16.107%\n",
      "25/149|16.779%\n",
      "26/149|17.45%\n",
      "27/149|18.121%\n",
      "28/149|18.792%\n",
      "29/149|19.463%\n",
      "30/149|20.134%\n",
      "31/149|20.805%\n",
      "32/149|21.477%\n",
      "33/149|22.148%\n",
      "34/149|22.819%\n",
      "35/149|23.49%\n",
      "36/149|24.161%\n",
      "37/149|24.832%\n",
      "38/149|25.503%\n",
      "39/149|26.174%\n",
      "40/149|26.846%\n",
      "41/149|27.517%\n",
      "42/149|28.188%\n",
      "43/149|28.859%\n",
      "44/149|29.53%\n",
      "45/149|30.201%\n",
      "46/149|30.872%\n",
      "47/149|31.544%\n",
      "48/149|32.215%\n",
      "49/149|32.886%\n",
      "50/149|33.557%\n",
      "51/149|34.228%\n",
      "52/149|34.899%\n",
      "53/149|35.57%\n",
      "54/149|36.242%\n",
      "55/149|36.913%\n",
      "56/149|37.584%\n",
      "57/149|38.255%\n",
      "58/149|38.926%\n",
      "59/149|39.597%\n",
      "60/149|40.268%\n",
      "61/149|40.94%\n",
      "62/149|41.611%\n",
      "63/149|42.282%\n",
      "64/149|42.953%\n",
      "65/149|43.624%\n",
      "66/149|44.295%\n",
      "67/149|44.966%\n",
      "68/149|45.638%\n",
      "69/149|46.309%\n",
      "70/149|46.98%\n",
      "71/149|47.651%\n",
      "72/149|48.322%\n",
      "73/149|48.993%\n",
      "74/149|49.664%\n",
      "75/149|50.336%\n",
      "76/149|51.007%\n",
      "77/149|51.678%\n",
      "78/149|52.349%\n",
      "79/149|53.02%\n",
      "80/149|53.691%\n",
      "81/149|54.362%\n",
      "82/149|55.034%\n",
      "83/149|55.705%\n",
      "84/149|56.376%\n",
      "85/149|57.047%\n",
      "86/149|57.718%\n",
      "87/149|58.389%\n",
      "88/149|59.06%\n",
      "89/149|59.732%\n",
      "90/149|60.403%\n",
      "91/149|61.074%\n",
      "92/149|61.745%\n",
      "93/149|62.416%\n",
      "94/149|63.087%\n",
      "95/149|63.758%\n",
      "96/149|64.43%\n",
      "97/149|65.101%\n",
      "98/149|65.772%\n",
      "99/149|66.443%\n",
      "100/149|67.114%\n",
      "101/149|67.785%\n",
      "102/149|68.456%\n",
      "103/149|69.128%\n",
      "104/149|69.799%\n",
      "105/149|70.47%\n",
      "106/149|71.141%\n",
      "107/149|71.812%\n",
      "108/149|72.483%\n",
      "109/149|73.154%\n",
      "110/149|73.826%\n",
      "111/149|74.497%\n",
      "112/149|75.168%\n",
      "113/149|75.839%\n",
      "114/149|76.51%\n",
      "115/149|77.181%\n",
      "116/149|77.852%\n",
      "117/149|78.523%\n",
      "118/149|79.195%\n",
      "119/149|79.866%\n",
      "120/149|80.537%\n",
      "121/149|81.208%\n",
      "122/149|81.879%\n",
      "123/149|82.55%\n",
      "124/149|83.221%\n",
      "125/149|83.893%\n",
      "126/149|84.564%\n",
      "127/149|85.235%\n",
      "128/149|85.906%\n",
      "129/149|86.577%\n",
      "130/149|87.248%\n",
      "131/149|87.919%\n",
      "132/149|88.591%\n",
      "133/149|89.262%\n",
      "134/149|89.933%\n",
      "135/149|90.604%\n",
      "136/149|91.275%\n",
      "137/149|91.946%\n",
      "138/149|92.617%\n",
      "139/149|93.289%\n",
      "140/149|93.96%\n",
      "141/149|94.631%\n",
      "142/149|95.302%\n",
      "143/149|95.973%\n",
      "144/149|96.644%\n",
      "145/149|97.315%\n",
      "146/149|97.987%\n",
      "147/149|98.658%\n",
      "148/149|99.329%\n",
      "149/149|100.0%\n"
     ]
    }
   ],
   "source": [
    "#PRoceso completo\n",
    "archivo= 'Pkl/df_temp.pkl'\n",
    "# Cargar el DataFrame desde el archivo .pkl\n",
    "with open(archivo, 'rb') as archivo_pkl:\n",
    "    submatrices_diccionario_trabajadas = pickle.load(archivo_pkl)\n",
    "\n",
    "archivo= 'Pkl/train_dict_Columnas_worked.pkl'\n",
    "# Cargar el DataFrame desde el archivo .pkl\n",
    "with open(archivo, 'rb') as archivo_pkl:\n",
    "    train_dict_Columnas_worked = pickle.load(archivo_pkl)\n",
    "train_dict={}\n",
    "train_dict['Columnas_Worked']=train_dict_Columnas_worked\n",
    "memoria_disponible()\n",
    "\n",
    "\n",
    "\n",
    "for submatriz in submatrices_diccionario_trabajadas.keys():\n",
    "    print(str(submatriz)+ '/' + str(len(list(submatrices_diccionario_trabajadas.keys()))) +'|'+str(round(submatriz/len(list(submatrices_diccionario_trabajadas.keys()))*100,3))+'%')\n",
    "    Duminizar_numpy(submatriz)\n",
    "\n",
    "Dict_Columnas_Dummizadas\n",
    "valores_unicos = np.unique([valor for array in Dict_nombres_de_columnas_df_dummizadas.values() for valor in array])\n",
    "\n",
    "for submatriz in Dict_Columnas_Dummizadas.keys():\n",
    "    print(str(submatriz)+ '/' + str(len(list(Dict_nombres_de_columnas_df_dummizadas.keys()))) +'|'+str(round(submatriz/len(list(Dict_nombres_de_columnas_df_dummizadas.keys()))*100,3))+'%')\n",
    "    Dict_all_Columns[submatriz]=ajustar_a_columnas_restantes(submatriz)\n",
    "    Dict_nombres_de_columnas_df_dummizadas[submatriz]=0\n",
    "\n",
    "Matriz_final = unir_y_borrar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'Pkl/df_final.pkl'\n",
    "with open(nombre_archivo, 'wb') as archivo_pkl:\n",
    "    pickle.dump(Matriz_final, archivo_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Canal_ID', 'Cluster_Agencia_ID', 'Cluster_Cliente_ID',\n",
       "       'Cluster_Producto', 'Cluster_Ruta_SAK', 'Demanda_uni_equil',\n",
       "       'Dev_proxima', 'Dev_uni_proxima', 'Precio_Promedio',\n",
       "       'Ratio Devoluciones_unit', 'Ratio_Devoluciones_valor',\n",
       "       'Semana_3.0', 'Semana_4.0', 'Semana_5.0', 'Semana_6.0',\n",
       "       'Semana_7.0', 'Semana_8.0', 'Semana_9.0', 'Venta_hoy',\n",
       "       'Venta_uni_hoy'], dtype='<U24')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  6.  ,  0.  , ...,  0.  , 25.14,  3.  ],\n",
       "       [ 7.  ,  6.  ,  0.  , ...,  0.  , 33.52,  4.  ],\n",
       "       [ 7.  ,  6.  ,  0.  , ...,  0.  , 39.32,  4.  ],\n",
       "       ...,\n",
       "       [ 1.  ,  7.  ,  0.  , ...,  1.  , 51.  ,  4.  ],\n",
       "       [ 1.  ,  7.  ,  0.  , ...,  1.  , 26.94,  3.  ],\n",
       "       [ 1.  ,  7.  ,  0.  , ...,  1.  , 10.4 ,  1.  ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matriz_final_ventas = Matriz_final[:,]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
